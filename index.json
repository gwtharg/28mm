[
{
	"uri": "https://gwtharg.github.io/28mm/site_documentation/hugo_install/",
	"title": "Hugo Simple Install",
	"tags": ["hugo", "install"],
	"description": "",
	"content": "Install Hugo If you wish to try Hugo on your desktop then the simple instructions below will point you to a single install file.\nThe following note is from gohugo.io which has more information on Hugo.\n Install Hugo on macOS, Windows, Linux, OpenBSD, FreeBSD, and on any machine where the Go compiler tool chain can run.\n There is lots of talk about “Hugo being written in Go”, but you don’t need to install Go to enjoy Hugo. Just grab a precompiled binary!\n Hugo is written in Go with support for multiple platforms. The latest release can be found at Hugo Releases.\nHugo currently provides pre-built binaries for the following:\nmacOS (Darwin) for x64, i386, and ARM architectures Windows Linux OpenBSD FreeBSD Hugo may also be compiled from source wherever the Go toolchain can run; e.g., on other operating systems such as DragonFly BSD, OpenBSD, Plan 9, Solaris, and others. See https://golang.org/doc/install/source for the full set of supported combinations of target operating systems and compilation architectures.\n"
},
{
	"uri": "https://gwtharg.github.io/28mm/paas/docker_automation/",
	"title": "Docker Automation",
	"tags": ["docker", "openshift", "gradle", "logstash"],
	"description": "",
	"content": "Logstash Example This document describes an example of the configuration and deployment of a Docker image in a RHEL environment, from a registry URL to the PaaS. It also goes over the CI/CD/Platform tools used in the process. Logstash is part of Centralised Logging on the platform, and is used to collect and manipulate system and application logs sent by fluentd log collectors  It resides on the PaaS and ships its logs to an external set of Elasticsearch VMs, currently in non-prod. This gives us a central way to manage and view large amounts of information in a quick fashion, using the Kibana front end. If you are interested have a read about the ELK stack  .\nThe files will match the layout of this working project  . There will be a note of what to change, should you want to build your own template.\nRequirements:  Access to the non-prod OpenShift environment \u0026amp; relevant platform components (if you wish to replicate) Some understanding of: Elasticsearch (ELK stack), Red Hat Linux, Gradle, Jenkins, Docker, Python, OpenShift  Github layout: We will use a standard for folder structure and Gradle commands to publish a copy of the image, assuming our project is called \u0026lsquo;myproject\u0026rsquo;\nmyproject/caboodle/ myproject/src/ myproject/src/docker/ myproject/src/templates/openshift/ Gradle files: To save some space \u0026amp; time here, I\u0026rsquo;ll refer to a working example for these files and mention what to change:\n This file is our \u0026lsquo;root\u0026rsquo; build, it refers to build and publish tasks contained in other build.gradle files, base repos, and any GoCD version information, which we\u0026rsquo;ll ignore for now.  myproject/build.gradle\n This file describes our dependencies, registry information and publishing to Caboodle/Nexus. Under dependencies we will just set a dependency on openshift-project to demonstrate. Our Logstash instance will only build once an instance of openshift-project becomes available.  /Caboodle/build.gradle\n This file describes the docker build itself  /src/docker/Dockerfile\nOther config files:  /openshift/template.json - How the OpenShift project should be configured, there are a few extra services configured here that can be ignored, but if building your own, replace references of \u0026lsquo;logstash\u0026rsquo; with your project name. It also contains Chieftain env variables which are explained later. myproject/settings.gradle - Defines our included submodules myproject/gradle.properties - Options to configure process used for the build. For a Docker image, change it to something unique (so the Caboodle Logstash isn\u0026rsquo;t overwritten), such as:  ... artifactName=myproject_logstash description=a test config of logstash ...  More info on the use of these two files  .\nDocker config:  Dockerfile the config for building the image logstash.conf for the base Logstash config required for startup, containing fields replaced by the Python script logstash_entrypoint.py is the script to pull Logstash Chieftain config \u0026amp; replace config values pip.conf has the Caboodle URL for installing Python libraries requirements.txt for the actual Python modules  A Docker image is what Logstash will be built and run as our container, to be eventually deployed on OpenShift. The Gradle components are needed to actually build and publish artifacts (including our image), and now we need to configure the image:\nA rhel7 image is used to give us the ability to install Logstash and configure Python libraries required for configuration management. /src/docker/Dockerfile/ also refers to requirements.txt in the parent directory, pointing torequests and pyyaml for REST calls to Chieftain and creation of a .yml file for our Logstash instance respectively.\nLogstash is installed, followed by Python \u0026amp; the module installer pip, Java (Logstash needs 1.8) and the libraries defined in requirements.txt.\nInstall details: Installation of Logstash and the necessary Python components\nRUN yum install -y logstash python2 python2-pip.noarch java \\ \u0026amp;\u0026amp; pip install -r /tmp/requirements.txt\nThe entrypoint is the default command to run when the Docker image starts, here we use the Python script itself. It is run to instrument the configuration of Logstash using our configuration data before the Logstash binary file is run, to ensure we have the most recent snapshot.\nENTRYPOINT [\u0026quot;python\u0026quot;,\u0026quot;/logstash_entrypoint.py\u0026quot;]\nLogstash requires a configuration file logstash.conf to start up, and it needs to point to a bunch of external Elastic non-prod VMs with some authentication, filtering and index config. The script will replace tagged fields in the local file with its Chieftain config, prior to copying it into the default Logstash config directory, and finally starting the Logstash executable that points to this config file.\nChieftain configuration: If we want to build and test the image locally (who doesn\u0026rsquo;t), we need the Chieftain instance and token id, which is automatically generated as environment variables when we build using Composer for an openshift-project. CHIEFTAIN_INSTANCEID, CHIEFTAIN_TOKENID have been provided in the script in debug mode so can be replaced for testing, otherwise they\u0026rsquo;re fetched as environment variables.\nRefer to this working project  to create a unique service component in Chieftain; create an instance and then grab the id. Refer \u0026lsquo;Logstash\u0026rsquo; in Chieftain  as an example.\nBuilding: To test locally, build the logstash image:\n docker build -t myproject .\nTo run (interactively):\ndocker run -it myproject \nTesting: If part of the build fails, it\u0026rsquo;s useful to run the container and investigate at that point, since we might back out too early (with a failed container) in later steps, e.g.\nStep 9 : COPY logstash_entrypoint.py / ---\u0026gt; Using cache ---\u0026gt; 3e14adcc988f docker run -it 3e14adcc988f\nOtherwise, executing a shell on the built image is good to see if everything\u0026rsquo;s in place, grabbing the container ID with the first command\ndocker ps\ndocker exec -it \u0026lt;container id\u0026gt; /bin/bash\nJenkins config: Again the document here  is great for describing the CI build job that will upload the Logstash artifacts (including the Docker image) to Nexus. I recommend using it to create the job. This  is the Jenkins build used for the project as an example.\nComposer: Next we need to Compose! This assumes we have:\n A complete \u0026amp; configured git layout A successful Jenkins build A Chieftain Logstash service component  Go to Composer  and type in the name of your service component, and search the group \u0026lsquo;docker\u0026rsquo; which was defined already in the build config. We can ignore tags for now (without a specific tag it will default to non-prod)\n Add a scale value of 1 Add an OpenShift project name \u0026lsquo;logstash-test\u0026rsquo;  The example json when \u0026lsquo;Compose\u0026rsquo; is selected should look like the below (versions may change). We are creating a new instance of openshift-project; if we want to deploy again in the same environment, we can reference an \u0026lsquo;existing\u0026rsquo; openshift_project - with tags \u0026lsquo;non-prod\u0026rsquo; in Chieftain.\nAfter a while Composer will give us a correlation ID, in the top right of the box, pasting it into Chieftain will provide us with details of the openshift-project and logstash instances now tied to it.\n{ \u0026quot;maven_name\u0026quot;: \u0026quot;com.bank.docker:logstash:0.0.45\u0026quot;, \u0026quot;scale\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;logstash\u0026quot;, \u0026quot;value\u0026quot;: 1 } ], \u0026quot;new_openshift_project_name\u0026quot;: \u0026quot;logstash-test\u0026quot; } GoCD: In GoCD  we\u0026rsquo;ll hopefully see a full set of green, where the trigger is the call by composer, the OpenShift project is created, and finally Logstash is deployed.\nAnd in non-prod  OpenShift, the project which has successfully deployed!\n"
},
{
	"uri": "https://gwtharg.github.io/28mm/paas/what_is_docker/",
	"title": "What is Docker?",
	"tags": ["docker", "openshift"],
	"description": "",
	"content": "Docker is an Open Source software development platform. It\u0026rsquo;s main benefit is to package applications into \u0026ldquo;containers\u0026rdquo;, allowing them to be portable and lightweight among any system running the Linux OS. Container technology has been around for a few years, with Solaris Zones, IBM Wpars etc, but the hype around Dockers approach to containers has pushed this technology to the forefront in the last couple of years.\nBenefits of Docker Containers Scalability Container technology allows for a much larger scale of applications in virtualised environment. With a perfectly tuned container, you can have 4-6 times the number of application instances as you can using VM\u0026rsquo;s on the equivalent hardware. This means you reducde the overhead of running a VM, leaving you a small container running your application.\nPortability Containers elimates the \u0026ldquo;it works ok on my machine\u0026rdquo; problem as the same docker container image will run across all Linux based OS platforms.\nSpeed of development Developers can quickly develop, test and deploy docker containers. They don\u0026rsquo;t need to worry about setting up complex development environments.\nCan be pre-packaged Application providers are now starting to ship their applications in pre-built containers. Gone are the days of building an environemnt then having to install your application, it comes already packaged for you.\nFor example, let\u0026rsquo;s dowmload a pre-packaged HTTP server from redhat and launch the docker image:\n docker pull rhscl/httpd-24-rhel7\n  Using default tag: latest Trying to pull repository registry.access.redhat.com/rhscl/httpd-24-rhel7 ... Pulling from registry.access.redhat.com/rhscl/httpd-24-rhel7 4e5a7647df47: Pull complete 0001a3087112: Pull complete 5027fa50d337: Pull complete 503dde528ea5: Pull complete Status: Downloaded newer image for registry.access.redhat.com/rhscl/httpd-24-rhel7:latest  docker run -d -p 8080:8080 registry.access.redhat.com/rhscl/httpd-24-rhel7\n Now navigate to your machines hostname/ip and use port 8080 and voila:\nHow to build a docker image The easiest way to build a docker image is to use an existing image and layer your changes on top of it. This then creates a newer version with your updates applied. Let\u0026rsquo;s take the above pre-packaged http server as an example.\nWe are going to place a simple Hello World index page into the image to display when you access the URL\nTo do this, we create a Dockerfile. this file tells the docker build process what to do. So in our case, we are going to say where the original docker image should come FROM and then COPY in our new index file:\n cat Dockerfile\n FROM registry.access.redhat.com/rhscl/httpd-24-rhel7 COPY index.html /opt/rh/httpd24/root/var/www/html/  cat index.html\n \u0026lt;P\u0026gt;Hello world Once we have our Dockerfile in place, we tell docker to build our image, and give it a new name:\n docker build -t new_http_image .\n Sending build context to Docker daemon 3.072 kB Step 1 : FROM registry.access.redhat.com/rhscl/httpd-24-rhel7 ---\u0026gt; 6bf22bf8b187 Step 2 : COPY index.html /opt/rh/httpd24/root/var/www/html/ ---\u0026gt; d23ebab73188 Removing intermediate container 625cd8470385 Successfully built d23ebab73188 Now that we have our new image, we can execute it:\n docker run -p 8080:8080 new_http_image\n Now navigate to your machines hostname/ip and use port 8080 and voila:\nAs we use Open Shift to deploy docker containers in CYB, please refer to the\nOpenShift OpenShift Documentation  for how to deploy a docker image in OpenShift\nReferences Docker.com  Docker on Wikipedia  "
},
{
	"uri": "https://gwtharg.github.io/28mm/paas/openshift/",
	"title": "OpenShift Container Platform",
	"tags": ["docker", "openshift", "kubernetes"],
	"description": "",
	"content": "Openshift is a Platform as a Service (PaaS) technology from Redhat based on Docker and Kubernetes.\nOpenshift provides the ability to orchistrate docker containers, providing request routing, health checks and automated scaling amongst other things.\nArchitecture Openshift is made up of multiple components that together orchestrate containers and allow them to talk to one another. There are multiple PaaS\u0026rsquo; deployed within the bank each with it\u0026rsquo;s own purpose.\n   PaaS Name Purpose     Non Production This PaaS is used for running the non production workloads, this will be where development and test purposes are deployed.   Production This PaaS is used to run production workloads which provide services to the customer.   Shared Services This PaaS is used to run the Operational Platform applications that are shared between Production and NonProduction PaaS\u0026rsquo;s. This is designed to run workloads that do not provide functionality to a customer but used to manage the Platform. This will run things like Composer, Kit CD services, Caboodle and Chieftain.    Openshift/Kubernetes Important Objects There are only a few important components that need to be understood to get started with Openshift.\nAll Openshift objects can be viewed and edited either in the UI or using the command line tool oc which is available from github.com (this will be packaged up eventually :-))\noc get ${object} will return the objects that you have access to.\nThis table provides a quick intro to some of the objects, further info can be found at the online documentation for Openshift and Kubernetes\n   Object oc get type (shortcut) Description     Project projects An area where a user can create and configure objects.   Namespace namespaces(ns) An extention of the project object, the namespace is a section of the SDN which is logically seperated from other namespaces.   Image Streams imagestreams (is) An object which is linked to a docker image deployed in the local docker registry of the PaaS. Other objects will refer to the imagestream rather than the docker images themselves. The image stream will track updates which can be used as a trigger for running deploys. Image streams also have tags similar to docker images (but they do not have to match the docker image tag)   Pod pods(po) A single deployable component which can be made up of 1 or more docker containers. This allows multiple docker containers to share a memory space, filesystem and network where there are tight dependencies.   Service services (svc) This is equivalent of a DNS entry and a load balancer when there are multiple instances of a pod running. This is only resolvable from containers running within the SDN of the PaaS.   Route routes This is the object that is used to configure the HA proxy\u0026rsquo;s when access is required to a service from outside of the PaaS.   Deployment Config deploymentconfigs(dc) Deployment configs are used to define how a docker image referenced by an imagestream should be deployed.   Replication Controllers replicationcontrollers(rc) A deployment config will create a replication controller rather than a pod. It is the replication controllers responsibility to create the pods, montior the health of the pods and start new pods if there are not enough pods running.   Persistent Volumes persistentvolumes(pv) These are filesystems which are shared amongst the nodes which can be mounted into a Pod when the docker container requests a Volume. This is a cluster level object whith various properties including size and write mode i.e. readWriteOnce(only a single instance of a pod can mount), readWriteMany(multiple instances of pods can mount), readOnly.   Persistent Volume Claim persistentvolumeclaims (pvc) These are used to allow a project to mark a persistent volume as used. A claim is really a request for a persistent volume which will then be matched and bound to a free volume. Each volume can only be bound to a single claim.    Whilst working on the PaaS it is possible to use a template to create multiple objects at a time. This is what elements relies on to do deploy applications to the Paas.\nUnderlying Fabric of the PaaS The PaaS is constructed with multiple types of physical servers. There are OpenShift Masters which are used to run the components used to manage the PaaS and OpenShift Nodes which are used to run the Pod workload.\n"
},
{
	"uri": "https://gwtharg.github.io/28mm/paas/pe_background/",
	"title": "Platform Engineering Background",
	"tags": ["openshift", "html"],
	"description": "",
	"content": " This is an embedded html page   \u0026nbsp;\nSome Background When the Platform Engineering team was formed there were a number of different processes in place for requesting work from the team. These included:\nProcess/MethodType of requestREAP Process / EPM\nPlanned project requests - Low detail and uncertain timingsEmailsUnplanned requests\nService Requests\nIncidents\nOCSMS Teams / HipchatWalkupService NowService Requests\nIncident Records\nProblem Records\nJiraPlanned Requests\nUnplanned Requests\nIncidents\nRTCIncidents\nUnplanned Requests\nSharepointUnplanned RequestsMeeting RequestsActions - should be plannedEscalationsUnplanned RequestsFollowing a review of the above the following requirements were captured:\nWhat is the team doing?How do we create headroom for the team?Minimise time spent managing work requestsClear prioritisation of tasks processHave good data about the work the team does to help decision makingPrimary tasks is to:\nRationalise work requests systems with defined SLAs\u0026nbsp;\n  "
},
{
	"uri": "https://gwtharg.github.io/28mm/git/branchingstrategy/",
	"title": "Branching and Merging Strategy",
	"tags": ["git"],
	"description": "",
	"content": "Most development is done on the internal Github but some code is shared with the external Bitbucket. In order to support this we have the same repo pushed to both GitHub and BitBucket.\nIt is best to consider GitHub and BitBucket as simply copies of the same git repository. There is no merging between GitHub and BitBucket, merging is done at the branch level and the same commit history is pushed to both systems.\nThere are slightly different strategies depending on what we are modifying.\nCommon Libraries Common libraries are strongly synchronised. All work for PaaS is done on a 2.0 branch and whenever a change is made on bitbucket/2.0 is must also be pushed to github/2.0 or vice versa.\nAs required the latest DYB changes on bitbucket/master branch will be merged into bitbucket/2.0 and pushed to github/2.0.\nNew Microservices This is the simplest scenario where a new repo is created on Github and development continues on github/master.\nOn a regular basis github/master is pushed to bitbucket/master so that in theory work could be done by people not on the network.\nExisting Microservices Initially bitbucket/master is pushed to github/master and a bitbucket/2.0 marker branch is created pointing to the same commit. Migration then continues on github/master.\nPeriodically we will have to synchronise any changes that have been made by DYB which involves merging bitbucket/master into github/master. The bitbucket/2.0 marker is moved to point to the merge commit and is pushed back to bitbucket.\nNote: Be very careful not to merge any PaaS work back into bitbucket/master since that belongs to DYB.\nAlexa - ScreenMedia ScreenMedia have their own git workflow and will periodically raise a pull request to merge their development branch into bitbucket/master. When this is merged it is pushed to github/master so that it can be built and deployed to the PaaS.\nNote: Since they are using a different workflow which uses a long lived development branch you should NOT delete their branch when merging. For the same reason do not rewrite history by rebasing or squashing during the merge, stick with standard merges.\n"
},
{
	"uri": "https://gwtharg.github.io/28mm/site_documentation/markdown_notes/",
	"title": "Markdown Notes",
	"tags": ["markdown", "help"],
	"description": "",
	"content": "Tables You can create tables by assembling a list of words and dividing them with hyphens - (for the first row), and then separating each column with a pipe |:\nso this\n First Header | Second Header ------------ | ------------- Content from cell 1 | Content from cell 2 Content in the first column | Content in the second column Renders as this\n   First Header Second Header     Content from cell 1 Content from cell 2   Content in the first column Content in the second column    Headers # H1 ## H2 ### H3 #### H4 ##### H5 ###### H6 H1 H2 H3 H4 H5 H6 Emphasis, aka italics, with asterisks or underscores.\nStrong emphasis, aka bold, with **asterisks** or __underscores__. Strong emphasis, aka bold, with asterisks or underscores.\nStrikethrough uses two tildes. ~~Scratch this.~~ Strikethrough uses two tildes. Scratch this.\nOrdered Lists (In this example, leading and trailing spaces are shown with with dots: ⋅)\n1. First ordered list item 2. Another item 1. Actual numbers don't matter, just that it's a number 4. And another item.  First ordered list item Another item Actual numbers don\u0026rsquo;t matter, just that it\u0026rsquo;s a number And another item.  Unordered Lists To create an unordered list, add dashes (-), asterisks (*), or plus signs (+) in front of line items. Indent one or more items to create a nested list.\n* First item * * Second item * * Third item * * Fourth item * - First item - - Second item - - Third item - - Indent 1 `tab then -` - Indent 2 `tab then -` - Fourth item - + First item + + Second item + + Third item + + Fourth item +  First item * Second item * Third item * Fourth item *   First item - Second item - Third item -  Indent 1 tab then - Indent 2 Tab then -   Fourth item -   First item + Second item + Third item + Fourth item +  Lists with Tick boxes - [x] First item - [ ] Second item - [ ] Third item  First item Second item Third item  Line Breaks To create a line break \u0026lt;br\u0026gt;, end a line with two or more spaces, and then type return.\n So this would be a very long line that could with a line break now. [this is where the return was after two spaces] Now we have another line which will be after the line break. So this would be a very long line that could with a line break now. Now we have another line which will be after the line break.\nBlockquotes To create a blockquote, add a \u0026gt; in front of a paragraph.\n\u0026gt; So we should see this text in a block quote.  So we should see this text in a block quote.\n Horizontal Rules To create a horizontal rule, use three or more asterisks (***), dashes (\u0026mdash;), or underscores (___) on a line by themselves.\n*** --- ___    Links with names To create a link, enclose the link text in brackets (e.g., [Duck Duck Go]) and then follow it immediately with the URL in parentheses (e.g., (https://duckduckgo.com)).\nA better search engine would be [Duck Duck Go](https://duckduckgo.com) A better search engine would be Duck Duck Go\nRaw Links and Email Addresses To create a link or an email link , enclose the link text in angled brackets\nhttps://duckduckgo.com or yourname@home.com\n\u0026lt;https://duckduckgo.com\u0026gt; or \u0026lt;yourname@home.com\u0026gt; "
},
{
	"uri": "https://gwtharg.github.io/28mm/git/",
	"title": "GIT Info",
	"tags": ["git"],
	"description": "",
	"content": "Test from GIT MD files Based on notes from old V: Drive from hVM\n  GIT Tagged files   Branching and Merging Strategy   Semantic Version Enforcement   "
},
{
	"uri": "https://gwtharg.github.io/28mm/site_documentation/shortcode_test/",
	"title": "Shortcodes",
	"tags": ["hugo", "html", "markdown", "shortcodes"],
	"description": "",
	"content": " Due to some restrictions in displaying the rendered code please note that in the code snippets we show there is no leading or training spaces between the {{ and the \u0026lt; or % as shown in some of the descriptions.\n highlighting with shortcodes  {{\u0026lt; highlight go \u0026gt;}} Code to highlight here. {{\u0026lt; /highlight \u0026gt;}}\n Code to highlight here. button shortcode creates a button Changing the href to an external link works too.\n {{\u0026lt; button href=\u0026quot;/28mm/site_documentation/flowcharts/\u0026quot; \u0026gt;}}Site Content Info{{\u0026lt; /button \u0026gt;}}\n Site Content Info  rawhtml shortcode This allows us to enter html within a shortcode and run within a markdown file. We now can leverage html to enhance our markdown.\nTo show the code here we had to used an Entity Encoder. Entity Encoder  This is the code and the rawhtml shortcode to allow html colours in our example.\n {{\u0026lt; rawhtml\u0026gt;}}\n \u0026lt;h2\u0026gt;HTML embedded in Markdown\u0026lt;/h2\u0026gt; Some text with \u0026lt;span style=\u0026quot;color:blue\u0026quot;\u0026gt; Simple \u0026lt;b\u0026gt;blue\u0026lt;/b\u0026gt; coloured text.\u0026lt;br\u0026gt; \u0026lt;/span\u0026gt;Back to normal text. Now we can highlight in \u0026lt;span style=\u0026quot;color:red\u0026quot;\u0026gt; \u0026lt;b\u0026gt;red\u0026lt;\u0026gt; /b\u0026gt; this is red.\u0026lt;/span\u0026gt;\u0026lt;br\u0026gt;  {{\u0026lt; /rawhtml \u0026gt;}}\n  HTML embedded in Markdown Some text with Simple blue coloured text.\nBack to normal text. Now we can highlight in red this is red.\nmermaid shortcode diagrams {{ \u0026lt; mermaid \u0026gt;}} graph LR; A[Hard edge] --\u0026gt;|Link text| B(Round edge) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result one] C --\u0026gt;|Two| E[Result two] {{ \u0026lt; /mermaid \u0026gt;}}  graph LR; A[Hard edge] --|Link text| B(Round edge) B -- C{Decision} C --|One| D[Result one] C --|Two| E[Result two]  More examples of mermaid can be found here. mermaid examples  expand shortcode   {{\u0026#x3C;expand\u0026#x3E; }} This is where we keep our additional expandable text. {{\u0026#x3C; /expand\u0026#x3E; }}     Expand me...   This is where we keep our additional expandable text.   notice note shortcode   {{ % notice note % }} Your notice goes here. {{ % /notice note % }}   Your notice goes here.\n "
},
{
	"uri": "https://gwtharg.github.io/28mm/",
	"title": "Auto-Doc",
	"tags": [""],
	"description": "",
	"content": "Auto-Doc Sample Front Matter Hugo Front Matter is the sites Metadata --- title: \u0026#34;You Title goes here\u0026#34; date: 2020-04-13T17:36:16+01:00 draft: true tags: [ \u0026#34;if required\u0026#34; ] categories: [ \u0026#34;Your category here\u0026#34; ] components: [\u0026#34;Jira aligned component\u0026#34;] authors: [\u0026#34;name of document owner\u0026#34;] --- A weight can be added to a page within a chapter. Similar to pinning a post. Also fields like tags: can be blank [\u0026quot;\u0026quot;] initially if you are unsure of content.\n Taxonomy Links  Categories in Hugo  Components in Hugo  Tags in Hugo  Authors in Hugo  "
},
{
	"uri": "https://gwtharg.github.io/28mm/paas/",
	"title": "Paas",
	"tags": ["openshift"],
	"description": "",
	"content": "Training Notes  Docker Automation   What is Docker?   OpenShift Container Platform   Platform Engineering Background   "
},
{
	"uri": "https://gwtharg.github.io/28mm/tfs/",
	"title": "TFS Internal",
	"tags": [""],
	"description": "",
	"content": "Imported via Pandoc Pages based on TFS documents  Team Types   "
},
{
	"uri": "https://gwtharg.github.io/28mm/authors/",
	"title": "Authors",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/components/",
	"title": "Components",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/authors/cybg/",
	"title": "cybg",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/docker/",
	"title": "docker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/components/docker/",
	"title": "docker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/gradle/",
	"title": "gradle",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/logstash/",
	"title": "logstash",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/openshift/",
	"title": "openshift",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/components/document/",
	"title": "document",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/html/",
	"title": "html",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/hugo/",
	"title": "hugo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/categories/hugo/",
	"title": "hugo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/markdown/",
	"title": "markdown",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/shortcode/",
	"title": "shortcode",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/shortcodes/",
	"title": "shortcodes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/authors/walmo/",
	"title": "walmo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/components/go/",
	"title": "go",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/components/hugo/",
	"title": "hugo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/install/",
	"title": "install",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/site_documentation/flowcharts/",
	"title": "Flowcharts Notes",
	"tags": ["help", "mermaid", "shortcodes"],
	"description": "",
	"content": "Here are some mermaid diagrams using shortcodes {{ \u0026lt; mermaid \u0026gt;}} graph LR; A[Hard edge] --\u0026gt;|Link text| B(Round edge) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result one] C --\u0026gt;|Two| E[Result two] {{ \u0026lt; /mermaid \u0026gt;}}  graph LR; A[Hard edge] --|Link text| B(Round edge) B -- C{Decision} C --|One| D[Result one] C --|Two| E[Result two]  Gantt Diagrams {{ \u0026lt; mermaid \u0026gt;}} gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid section A section Completed task :done, des1, 2020-01-06,2020-01-08 Active task :active, des2, 2020-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2020-01-06,24h Implement parser and json :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to mermaid :1d {{ \u0026lt; /mermaid \u0026gt;}}  gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid section A section Completed task :done, des1, 2020-01-06,2020-01-08 Active task :active, des2, 2020-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2020-01-06,24h Implement parser and json :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to mermaid :1d  Class Diagrams {{ \u0026lt; mermaid \u0026gt;}} classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 \u0026lt;--\u0026gt; C2: Cool label {{ \u0026lt; /mermaid \u0026gt;}}  classDiagram Class01 C2 : Where am i? Class09 --* C3 Class09 --| Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08  C2: Cool label  Git Graphs {{ \u0026lt; mermaid \u0026gt;}} gitGraph: options { \u0026quot;nodeSpacing\u0026quot;: 60, \u0026quot;nodeRadius\u0026quot;: 8 } end commit branch walmo checkout walmo commit commit checkout master commit commit merge walmo {{ \u0026lt; /mermaid \u0026gt;}}  gitGraph: options { \"nodeSpacing\": 60, \"nodeRadius\": 8 } end commit branch walmo checkout walmo commit commit checkout master commit commit merge walmo  Single Line {{ \u0026lt; mermaid \u0026gt;}} graph LR; HTML--\u0026gt;Hugo; {{ \u0026lt; /mermaid \u0026gt;}}  graph LR; HTML--Hugo;  Adding Comments {{ \u0026lt; mermaid \u0026gt;}} graph TD A[Client] --\u0026gt;|tcp_443 \u0026amp; tcp_8080| B(F5 Load Balancer) B --\u0026gt;|tcp_443| C[Live Server] B --\u0026gt;|tcp_443| D[Live Server] {{ \u0026lt; /mermaid \u0026gt;}}  graph TD A[Client] --|tcp_443 \u0026 tcp_8080| B(F5 Load Balancer) B --|tcp_443| C[Live Server] B --|tcp_443| D[Live Server]  TB Diagram {{ \u0026lt; mermaid \u0026gt;}} graph TB c1--\u0026gt;a2 subgraph one a1--\u0026gt;a2 end subgraph two b1--\u0026gt;b2 end subgraph three c1--\u0026gt;c2 end {{ \u0026lt; /mermaid \u0026gt;}}  graph TB c1--a2 subgraph one a1--a2 end subgraph two b1--b2 end subgraph three c1--c2 end  Colours with style {{ \u0026lt; mermaid \u0026gt;}} id1(Start)--\u0026gt;id2(Stop) style id1 fill:#f00,stroke:#333,stroke-width:4px style id2 fill:#0f0,stroke:#f66,stroke-width:2px,color:#fff,stroke-dasharray: 5, 5 {{ \u0026lt; /mermaid \u0026gt;}}  graph LR id1(Start)--id2(Stop) style id1 fill:#f00,stroke:#333,stroke-width:4px style id2 fill:#0f0,stroke:#f66,stroke-width:2px,color:#fff,stroke-dasharray: 5, 5  Circles {{ \u0026lt; mermaid \u0026gt;}} graph LR id1((Drawing a circle)) {{ \u0026lt; /mermaid \u0026gt;}}  graph LR id1((Drawing a circle))  "
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/help/",
	"title": "help",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/mermaid/",
	"title": "mermaid",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/content/",
	"title": "content",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/site_documentation/",
	"title": "Site Content Info",
	"tags": ["content", "help", "taxonomy"],
	"description": "",
	"content": "Basic help about the site   Our basic taxonomy comes from the Metadata in our \u0026lsquo;Front Matter\u0026rsquo;\nThis page has the following \u0026lsquo;Front Matter\u0026rsquo; taxonomy.\ntags: [\u0026quot;content\u0026quot; , \u0026quot;help\u0026quot; , \u0026quot;taxonomy\u0026quot;] catagories: [\u0026quot;help\u0026quot;] components: [\u0026quot;hugo\u0026quot;] authors: [\u0026quot;walmo\u0026quot;] Our types of taxonomy we are using are based on our configuration file.\nThe contents [\u0026ldquo;content\u0026rdquo; , \u0026ldquo;help\u0026rdquo; , \u0026ldquo;taxonomy\u0026rdquo;] we add when we create our file.\nMore accurate content in our Metadata will help users navigate the documents contained within the site.\n Hugo TOML YAML Mix config.toml uses TOML format:\ntitle = \u0026ldquo;My New Hugo Site\u0026rdquo;\nbut archetypes/default.md uses YAML\ntitle: \u0026ldquo;Test index\u0026rdquo;\nhttps://github.com/gohugoio/hugo/issues/5241\nThe reason is GitHub\u0026rsquo;s support for YAML front matter. Currently they do not support TOML front matter (Metadata).\nSo we are going to use **TOML** for the **config.toml** file then **YAML** for the rest of the contents.  Taxonomy Links  Categories in Hugo  Components in Hugo  Tags in Hugo  Authors in Hugo   Hugo Simple Install   Markdown Notes   Shortcodes   Flowcharts Notes   HTML Embedded Pages   PDF in HTML   Visio from Export   "
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/taxonomy/",
	"title": "taxonomy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/git/",
	"title": "git",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/categories/paas/",
	"title": "paas",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/components/sdlc/",
	"title": "sdlc",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/git/semanticversionenforcement/",
	"title": "Semantic Version Enforcement",
	"tags": ["git"],
	"description": "",
	"content": "Going forward the commit comment format will be enforced in GitHub, to allow semantic versioning of the builds. This is a basic development discipline to allow control and automation of code delivery.\nThis enforcement will be rolled out sympathetically to all GitHub repositories, so as not to interfere with the in flight releases.\nThis change consists off the format of the commit comments, from which the semantic version is derived and set of scripts to enforce and help with commits.\nCommit Comment Format Development will be done on branches, created from the mainline streams. Currently only have the master mainline stream, but as process matures will have stream for each major semantic version.\nThere will be two types of branches, normal development and hotfix. Normal development will be branched from the head of the mainline stream (master), while hotfix will be branched from a tagged release. All work must be done from a JIRA ticket.\nFor a normal development release the commit comment should be of the format given by the following regex\n^[A-Z]+-[[:digit:]]+ : (MAJOR|MINOR|PATCH) : [[:alnum:]]+\nThe first part if the JIRA ticket id, the second part is the semantic change, the third part is a description of the change. For example\nDYB-12345 : MINOR : An example comment\nNote the spacing around field separator (:), this is to simplify reading, making it consistently formatted.\nThe semantic version part, should should take the value, MAJOR, MINOR or PATCH, all upper case; as explained below\n MAJOR : A change that is backward breaking, currently this isn\u0026rsquo;t supported MINOR : A change that adds new functionality PATCH : A fix for existing functionality  The decision on the semantic version value should be done by the developer, the ticket author and if required the appropriate technical consultant.\nFor a hotfix the commit message should be of the format given by the following regex\n^[A-Z]+-[[:digit:]]+ : HOTFIX : [[:alnum:]]+\nFor example\nDYB-54321 : HOTFIX : Need this fixed now\nThese formats should be applied to all commits, including when merging pull requests. Github isn\u0026rsquo;t helpful here, as it pre-fills the merge commit message, the title of the merge box; this should be edited manually when merging.\nDetermination of Semantic Version The reason for enforcement of the commit comment is to determine the semantic version of the generated artefact.\nFor a normal change, on a mainline stream, the version of the generated artefact will be major.minor.patch for example 3.4.12.\nA build which publishes an artefact will check the last published release, by looking for the the last tag. If none is found it will take a default value. It will then look at all the commit comments since that tag, and look for the highest semantic version value in all the commit comments (MAJOR \u0026gt; MINOR |\u0026gt; PATCH). It will increment the semantic version and tag the code with the new version.\nFor example if the last tag was 3.4.12 and the commit comments since then are\nPE-3567 : PATCH : A bugfix\nPE-3371 : PATCH : Fix logic\nPE-3371 : MINOR : Add new endpoint\nThe highest semantic version value is MINOR, so the semantic version will be incremented to 3.5.0\nSee the document about versioning strategy for a fuller description of this semantic version incrementing.\nFor a hotfix release the semantic version will take the format major.minor.patch-hotfix.buildnumberfor example 3.4.12-hotfix.22.\nWhen the release build is run against a hotfix branch, it will find the last tag, which will be the tag that the hotfix branch was created against. It will take this tag and add the term -hotfix and its build number to the tag and then tag the code with the new tag. The use of the original tag allows multiple hotfix developments, and the use of the build number allows multiple attempts at each of the hot fixes.\nSemantic Version Tools A new directory has been added to the ms-template, called setup, which contains the tools to control semantic versioning. This will also be added to all other template used by auto-mate.\nThe scripts in this directory includes the hooks to enforce the commit patterns and scripts to work out the semantic version from the commit comments. See the README in the directory for more details.\nThere are two script of interest for any development activities.\nThe first is development-setup.sh, this sets up the hooks on the developers local copy of the git project. This is called by default for every build but running\ngradle setupDevelopment\nWill do it without running a build.\nThe second is create-hotfix.sh , this creates the hotfix branch. It requires the release tag of the artefact to be hot fixed as its only argument.\nThe other scripts are described at the end of the README.\n"
},
{
	"uri": "https://gwtharg.github.io/28mm/site_documentation/html_based_pages/",
	"title": "HTML Embedded  Pages",
	"tags": ["pdf", "html", "shortcode"],
	"description": "",
	"content": "  Trying colours You need to do this in html as markdown does not use colours by default.\n Some Markdown text with Simple blue coloured text.\nBack to normal text. Now we can highlight in red this is red.\n Below is the html for the colours    Some Markdown text with \u0026#x3C;span style=\u0026#x22;color:blue\u0026#x22;\u0026#x3E; Simple \u0026#x3C;b\u0026#x3E;blue\u0026#x3C;/b\u0026#x3E; coloured text.\u0026#x3C;br\u0026#x3E; \u0026#x3C;/span\u0026#x3E;Back to normal text. Now we can highlight in \u0026#x3C;span style=\u0026#x22;color:red\u0026#x22;\u0026#x3E; \u0026#x3C;b\u0026#x3E;red\u0026#x3C;/b\u0026#x3E; this is red.\u0026#x3C;/span\u0026#x3E;\u0026#x3C;br\u0026#x3E;   To show the code here we had to used an Entity Encoder. Entity Encoder  "
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/pdf/",
	"title": "pdf",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/components/shortcode/",
	"title": "shortcode",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/site_documentation/pdf_in_html/",
	"title": "PDF in HTML",
	"tags": ["pdf", "html", "shortcode"],
	"description": "",
	"content": "date: 2020-04-28T12:04:57+01:00 The html snippet is between our rawhtml shortcode.\n {{ \u0026lt; rawhtml \u0026gt; }} html here {{ \u0026lt; /rawhtml \u0026gt; }}\n   This is embedded html in a markdown file  The href is from localhost in this test   \u0026#x3C;object data=\u0026#x22;/28mm/site_documentation/image/twd.pdf\u0026#x22; type=\u0026#x22;application/pdf\u0026#x22; width=\u0026#x22;800px\u0026#x22; height=\u0026#x22;834px\u0026#x22;\u0026#x3E; \u0026#x3C;embed src=\u0026#x22;/28mm/site_documentation/image/twd.pdf\u0026#x22;\u0026#x3E; \u0026#x3C;p\u0026#x3E;This browser does not support PDFs. Please download the PDF to view it: \u0026#x3C;a href=\u0026#x22;http://localhost/28mm/site_documentation/image/twd.pdf\u0026#x22;\u0026#x3E;Download PDF\u0026#x3C;/a\u0026#x3E;.\u0026#x3C;/p\u0026#x3E; \u0026#x3C;/embed\u0026#x3E; \u0026#x3C;/object\u0026#x3E;   This browser does not support PDFs. Please download the PDF to view it: Download PDF.\n   "
},
{
	"uri": "https://gwtharg.github.io/28mm/components/openshift/",
	"title": "openshift",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/categories/help/",
	"title": "help",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/categories/help-document/",
	"title": "help, document",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/site_documentation/visio_from_export/",
	"title": "Visio from Export",
	"tags": ["visio, convert, help, pdf"],
	"description": "",
	"content": "This is a jpg export from Visio This is a png export from Visio  Using the rawhtml shortcode to embedded html   This is a Visio Drawing exported as a PDF  There is more user control over this type of file   \u0026#x3C;object data=\u0026#x22;/28mm/site_documentation/image/rts_pdf.pdf\u0026#x22; type=\u0026#x22;application/pdf\u0026#x22; width=\u0026#x22;800px\u0026#x22; height=\u0026#x22;834px\u0026#x22;\u0026#x3E; \u0026#x3C;embed src=\u0026#x22;/28mm/site_documentation/image/rts_pdf.pdf\u0026#x22;\u0026#x3E; \u0026#x3C;p\u0026#x3E;This browser does not support PDFs. Please download the PDF to view it: \u0026#x3C;a href=\u0026#x22;http://localhost/28mm/site_documentation/image/rts_pdf.pdf\u0026#x22;\u0026#x3E;Download PDF\u0026#x3C;/a\u0026#x3E;.\u0026#x3C;/p\u0026#x3E; \u0026#x3C;/embed\u0026#x3E; \u0026#x3C;/object\u0026#x3E;   This browser does not support PDFs. Please download the PDF to view it: Download PDF.\n   "
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/visio-convert-help-pdf/",
	"title": "visio, convert, help, pdf",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/document/",
	"title": "document",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/components/git/",
	"title": "git",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/components/help/",
	"title": "help",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/kubernetes/",
	"title": "kubernetes",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/tfs/team_types/",
	"title": "Team Types",
	"tags": ["TFS", "document"],
	"description": "",
	"content": "Test snippet from document Aim of the Document This document is an attempt to guide TFS administrators through the process required to create a more complex hierarchical structure under the VM project folder.\nWe will run through an example using the IIB Technical Team to guide you through the process.\nInitial Considerations Most importantly is that we have had a discussion with the users to understand what it they wish to achieve. If teams require to view the results of queries from other teams \u0026amp; have the ability to show those on a common dashboard then this may be a reason to create a more complex structure. If the user just requires to be a member of many teams then this is not a valid reason to create a more complex structure.\nNote \u0026ndash; rights to view work/code/queries will be inherited with this model. So any team on a lower level must consent to this before creating any complex structure.\n"
},
{
	"uri": "https://gwtharg.github.io/28mm/tags/tfs/",
	"title": "TFS",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://gwtharg.github.io/28mm/components/tfs/",
	"title": "TFS",
	"tags": [],
	"description": "",
	"content": ""
}]